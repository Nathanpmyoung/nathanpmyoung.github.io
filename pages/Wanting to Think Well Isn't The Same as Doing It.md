- [[Blog]]
- *It feels good to have my own criticisms of something I love. So that when people criticise it, I can say "well I think there are some good reasons for criticism". There is an enjoyment to not being a rube, not being fully taken in. In that spirit be wary of the following criticism, because it was fun to write.*
- Wanting to think well isn't the same as doing it. [[Effective Altruism]]s want to think well. Here is some evidence:
	- They spend a lot of time discussing their thoughts.
	- They talk about [[Epistemics]].
	- They are interested in forecasting.
	- They say things like, "Tell me what would change your mind," or "What's the evidence of that?"
- Thinking well, like being good, is something I judge on outcomes. Trying very hard but failing is still a failure.
- The world is so varied and complicated that there is no single pattern to think well. There is no single strategy that wins every game. There is no rule without exceptions, probably including this one. So, there is no substitute for trying to actually think well, again and again. I doubt I've conveyed this very well, so I'm just going to keep repeating the same thing in different ways, hoping that it will somehow go through:
	- Consider the game of rock, paper, scissors. There is no way to always win. If you found some strategy that told you the exact order or the probabilities to win, then someone else would merely need to know that strategy. If you always used it, they could always beat you. This is what it's like being in an adversarial environment with players who can also take the same set of actions that you can. For any set of good actions you take, someone else can figure out a way to counteract it. There is no way around this.
	  
	  Luckily, most of the time, no one is interested enough in our actions to try to do so. And often, the cost is prohibitive. In the film The Truman Show, it's extremely expensive to build an entire fake world. It's unlikely this is happening to you. However, this does mean that there isn't necessarily a strategy that works in every situation.
	- Alternatively, it's hard to predict the future of knowledge. If there were a way to just think well about everything, it seems likely we would already know and predict everything. Going forward, we would know exactly what's going to happen. Yet, as David Deutsch rightly points out, the creation of future knowledge is unpredictable. And so decisions based on that knowledge are unpredictable too.
	- The world could turn out to be weird in a way that we find hard to think about right now. Heuristics don't always scale. Often, it seems like there's a rule of thumb which applies everywhere, but sometimes that's because we're applying it in places it shouldn't be applied.
	  
	  Take the example of throwing a ball from a moving car. The ball moves at roughly the speed at which you throw it plus the speed of the car. This seems so obvious that it should be the case, but it just turns out that it's not.
	- Eliezer Yudkowsky talks about the last virtue of rationality being unnamed. The reason he leaves it unnamed is, well, I'll just quote him.
	-
- The point he's trying to make, I think, is that if he were to name it, then everyone would merely note down the name and move on. And that's not what he's hoping for.